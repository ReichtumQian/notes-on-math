## 优化问题及其分类
- ### 优化问题
- 优化问题：考虑 $n$ 维空间中的优化问题，$Q \subseteq \mathbb{R}^n$，寻找 $x = (x^{(1)},\cdots,x^{(n)})^T \in Q$ 满足
  
  $$\min f_0(x), ~ \mathrm{s.t.} ~ f_j(x) \& 0, \quad j = 1,2,\cdots,m, $$
  
  其中 $\&$ 可以是 $\geq, \leq, =$，$f_0(x)$ 为目标函数，$f(x) := (f_1(x),\cdots,f_m(x))^T$ 是函数限制，定义可行集
  
  $$ \mathscr{F} := \{x \in Q | f_j(x) \& 0, \quad j = 1,\cdots,m\}. $$
-
- ### 优化问题的分类
- 约束问题：$\mathscr{F} \subset \mathbb{R}^n$ 且 $\mathscr{F} \neq \mathbb{R}^n$
- [[无约束优化问题]]：$\mathscr{F} = \mathbb{R}^n$
- 光滑问题：$f_j(\cdot)$ 都是可微的
- 线性约束问题：函数限制都是 [[仿射变换]]
- 线性优化问题：目标函数和约束函数都是 [[仿射变换]]
- 凸优化：定义域是 [[凸集]]，且目标函数为 [[凸函数]]。往往分为 [[光滑凸优化问题]] 和 [[非光滑凸优化]]。
-
- ### 可行与严格可行
- 可行与严格可行：若 $\mathscr{F} \neq \emptyset$ 则称优化问题为可行的，若 $x \in Q$ 满足函数限制中的条件都强化为严格不等号（如 $\geq$ 强化为 $>$），则称其为严格可行的。
-
- ## 优化算法模型及其分类
- ### 优化算法模型
- 假设我们要解决问题 $P$，我们往往会使用方法 $\mathscr{M}$ 解决一类问题 $\mathscr{P}$。由于 $\mathscr{P}$ 是宽泛的一类问题，我们需要抽取 $P$ 的一些特征信息，该流程由 Oracle $\mathscr{O}$ 完成，我们将数值算法假设已知的条件称为模型 $\Sigma$。在实际求解中，还需要确定精度 $\epsilon$ 或者终止条件 $\mathscr{T}_\epsilon$。我们最终将问题记为
  
  $$ \mathscr{P} \equiv (\Sigma, \mathscr{O}, \mathscr{T}_{\epsilon}) $$
- Local Black Box 思想：允许算法关注局部的信息而非全局整体信息，获取局部的函数值称为 Zero-order oracle，函数值以及梯度称为 First-order oracle，函数值、梯度、黑塞矩阵称为 Second-order oracle。
-
- ### 优化算法的性能
- Performance：由 Model 最差的问题表现决定
-
- ### 优化算法分类
- General Global Optimization：寻找连续函数的全局最小值
- General Nonlinear Optimization：寻找可微函数的局部最小值
- Black Box Convex Optimization：寻找凸集凸函数的全局最小值
- Structural Optimization：
-
- ## 参考资料
- 参考书：[Lectures on Convex Optimization](https://www.123pan.com/s/plj7Vv-Z3223.html)
- 参考课程：[Lecture 1 | Convex Optimization I (Stanford) (youtube.com)](https://www.youtube.com/watch?v=McLq1hEq3UY&ab_channel=Stanford)
-