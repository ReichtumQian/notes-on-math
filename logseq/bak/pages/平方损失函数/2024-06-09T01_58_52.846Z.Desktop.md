- 平方损失函数（Quadratic Loss Function）是 [[机器学习]] 中常用的损失函数，常常用于预测标签 $\mathcal{Y}$ 为实数子集的情况。
-
- **定义**(平方损失函数). 给定数据集 $\{x^{(i)}, y^{(i)}\}_{i = 1}^M$，模型 $h(x;\theta)$ 对应的平方损失函数为

  $$ \mathcal{L}(\mathbf{y}, h(\mathbf{x};\theta)) := \frac{1}{2} (h(x^{(i)};\theta) - y^{(i)})^2. $$
  
  其中 $\mathbf{x}, \mathbf{y}$ 表示 $\{x^{(i)}\},\{y^{(i)}\}$。
-
-
- ## 平方损失函数的概率论解释
- 线性回归求解中往往都使用平方误差，本节分析其用意。假设有 $M$ 个数据集 $(x^{(1)}, y^{(1)}), \cdots, (x^{(M)}, y^{(M)})$，其中 $x^{(i)} \in \mathbb{R}^n, y^{(i)} \in \mathbb{R}$，假设数据集会有误差
  
  $$ y^{(i)} = \theta^T x^{(i)} + \epsilon^{(i)},$$
  
  其中 $\epsilon^{(i)} \sim \mathcal{N}(0, \sigma^2)$ 服从 [[正态分布]]，此时满足 $x^{(i)}$ 条件下 $y^{(i)}$ 出现的概率为 $y^{(i)}|x^{(i)} \sim \mathcal{N}(\theta^T x^{(i)}, \sigma^2)$，其中 $\theta$ 为参数（选择正态分布的原因是 [[Lindeberg-Levy 中心极限定理]]）。
- 考虑 [[似然函数]] $L(\theta; X, \mathbf{y}) = p(\mathbf{y} |X; \theta)$，其中 $X = [(x^{(1)})^T, \cdots, (x^{(M)})^T]^T$，$\mathbf{y} = [y^{(1)},\cdots, y^{(M)}]^T$，则
  
  $$
  \begin{align*}
  L(\theta) &= \prod \limits_{i = 1}^M p(y^{(i)}|x^{(i)}; \theta)\\
  &= \prod \limits_{i = 1}^n \frac{1}{\sqrt{2\pi}\sigma} \mathrm{exp}\left( - \frac{(y^{(i)} - \theta^T x^{(i)})^2}{2 \sigma^2} \right)
  \end{align*}
  $$
  
  似然函数表达着各个 $\theta$ 参数取值情况下观测数据的合理性，我们希望最大化似然函数，不妨对似然函数取对数
  
  $$
  \begin{align*}
  \ell(\theta) &= \log L(\theta) = n \log \frac{1}{\sqrt{2\pi}\sigma} - \frac{1}{\sigma^2} \cdot \frac{1}{2} \sum\limits_{i = 1}^M (y^{(i)} - \theta^T x^{(i)})^2.
  \end{align*}
  $$
  
  因此要最大化似然函数即最小化 $\frac{1}{2} \sum\limits_{i = 1}^n (y^{(i)} - \theta^T x^{(i)})^2$。
-
-
-
